{"class":"org.apache.spark.ml.feature.RegexTokenizer","timestamp":1674904166680,"sparkVersion":"3.3.1","uid":"regexTok_951122b888d2","paramMap":{"pattern":"\\W+","inputCol":"text","outputCol":"tokens"},"defaultParamMap":{"gaps":true,"minTokenLength":1,"pattern":"\\s+","outputCol":"regexTok_951122b888d2__output","toLowercase":true}}
